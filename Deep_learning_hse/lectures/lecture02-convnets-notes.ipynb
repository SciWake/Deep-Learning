{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb733aa8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Обратное распространение ошибки</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1 Обучение нейронных сетей</h1>\n",
    "\n",
    "* Все слои обычно дифференцируемы, поэтому можно посчитать производные по всем параметрам.\n",
    "\n",
    "<img src='img/lecture02/1.png'>\n",
    "\n",
    "* $\\large a(x) = \\text{FC}_2(f(\\text{FC}_1(x)))$\n",
    "\n",
    "Параметры содержатся внутри $\\text{FC}_1, \\text{FC}_2$, так как полносвязные слои это набор линейных моделей с некоторыми весами, которые необходимо обучить. Для обучения зписываем функционал ошибки и минимизируем его:\n",
    "\n",
    "$$\\large \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} L(y_i, a(x_i)) \\to \\underset{a}{\\text{min}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04103c76",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">1.1 Как считать производные?</h2>\n",
    "\n",
    "<img src='img/lecture02/2.png'>\n",
    "\n",
    "На вход подаются два признака $x_1, x_2$, мы видим три полносвязных слоя:\n",
    "\n",
    "* Первый полносвязный слой - с некоторыми весами суммируем входные признаки и получаем два выходных числа $z_1, z_2$.\n",
    "* Выходы первого слоя $z_1, z_2$ суммируем с некоторыми весами и получаем два выходных числа $h_1, h_2$.\n",
    "* После $h_1, h_2$ суммируем с некоторыми коэффициентами и получаем прогноз модели.\n",
    "\n",
    "### На примере\n",
    "\n",
    "Стоит заметить, что в нашем примере нет нелинейности, так как это усложняет подсчеты. Возьмем конкретные веса для нашей нейронной сети:\n",
    "\n",
    "<img src='img/lecture02/3.png'>\n",
    "\n",
    "Посчитаем для наших входов значение каждого узла:\n",
    "\n",
    "<img src='img/lecture02/4.png'>\n",
    "\n",
    "Что если мы изменим выделенный вес $1$? Прогноз модели не изменится, так как в 3 слое входное значение равено $0$. Производная это характеристика того, насколько будет изменятся функция если мы будем изменять вход. Производная по весу будет говорить о том, насколько сильно изменится прогноз модели, если мы изменим данный вес. В нашем случае, производная будет равняться нулю. Поэтому нам необходимо изменить другой вес, для второго слоя у нейрона изменим вес равный $0$ на $1$:\n",
    "\n",
    "<img src='img/lecture02/5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac76a9",
   "metadata": {},
   "source": [
    "## Общий вид\n",
    "\n",
    "### Производная по $p_{11}$\n",
    "\n",
    "$$\\large a(x) = p_{11} h_1(x) + p_{21} h_2(x)$$\n",
    "\n",
    "<img src='img/lecture02/6.png'>\n",
    "\n",
    "Продифференцируем выход модели $a$ по весу $p_{11}$\n",
    "\n",
    "$$\\large \\frac{\\partial a}{\\partial p_{11}} = h_1(x)$$\n",
    "\n",
    "* Чем больше $h_1(x)$, тем сильнее $p_{11}$ влияет на $a$\n",
    "\n",
    "### Производная по $v_{11}$\n",
    "\n",
    "В данном случае, вместо $h_{1}$ мы подставляем чему равняется $h_1$\n",
    "\n",
    "$$\\large a(x) = p_{11} f(v_{11} z_1(x) + v_{21} z_2(x)) + p_{21} h_2(x)$$\n",
    "\n",
    "<img src='img/lecture02/7.png'>\n",
    "\n",
    "$$\\large \\frac{\\partial a}{\\partial v_{11}}  = \\frac{\\partial a}{\\partial h_{1}} \\frac{\\partial h_1}{\\partial v_{11}} = p_{11} \\cdot f^{'} z_{1}(x)$$\n",
    "\n",
    "Для нахождения производной модели по внутреннему весу, необходимо знать производную по более позднему слою."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c653a3",
   "metadata": {},
   "source": [
    "### Производная по $w_{11}$\n",
    "\n",
    "<img src='img/lecture02/8.png'>\n",
    "\n",
    "Как посчитать производную $a$ по $w_{11}$?\n",
    "\n",
    "$\\large \\frac{\\partial a}{\\partial w_{11}} = ?$\n",
    "\n",
    "Если мы запишем как зависит $a$ от $w_{11}$ и посчитаем производную, тогда это будет очень сложно. Воспользуемся другим подходом:\n",
    "\n",
    "* Как сильно изменяется $a$ при изменении $w_{11}$? Если мы будем изменять $v_{11}$, будет ли изменяться влияние на $w_{11}$ на выход? Конечно, так как $w_{11}$ влияет на $z_1$, а $z_{1}$ через $v_{11}$ влияет на выход.\n",
    "\n",
    "<img src='img/lecture02/9.png'>\n",
    "\n",
    "* Если мы будем изменять $v_{12}$, будет ли изменяться влияние на $w_{11}$ на выход? Будет, так как $w_{11}$ влияет на $z_1$, а $z_{1}$ через $v_{12}$ влияет на выход.\n",
    "\n",
    "<img src='img/lecture02/10.png'>\n",
    "\n",
    "* Если мы будем изменять $w_{22}$, будет ли изменяться влияние на $w_{11}$ на выход? Нет, так как $w_{11}$ влияет только $z_{1}$, то есть, $w_{22}$ не проходит через $w_{11}$.\n",
    "\n",
    "**Нахождение производной**\n",
    "\n",
    "<img src='img/lecture02/11.png'>\n",
    "\n",
    "Чтобы посчитать частную производную выхода по $w_{11}$, необходимо найти все пути, которые идут из $w_{11}$ в выход и просуммировать по каждому пути все частные производные:\n",
    "\n",
    "$$\\large \\frac{\\partial a}{\\partial w_{11}}  = \\frac{\\partial a}{\\partial h_{1}} \\frac{\\partial h_1}{\\partial z_{1}} \\frac{\\partial z_1}{\\partial w_{11}} +\\frac{\\partial a}{\\partial h_{2}} \\frac{\\partial h_2}{\\partial z_{1}} \\frac{\\partial z_1}{\\partial w_{11}}$$\n",
    "\n",
    "Так как $w_{11}$ влияет на $a$ через два пути, поэтому у нас два слогаемых. Вдоль каждого пути суммируем значения частных производных, производная $a$ по $h_{1}$, производная $h_1$ по $z_{1}$, производная $z_1$ по $w_{11}$ + ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55901d7b",
   "metadata": {},
   "source": [
    "## Метод обратного распространения ошибки\n",
    "\n",
    "Делаем вывод, чтобы посчитать производную по параметрам некоторого слоя, необходимо знать производные по параметрам более поздних слоев.\n",
    "\n",
    "<img src='img/lecture02/12.png'>\n",
    "\n",
    "* Мы как бы идём в обратную сторону по графу и считаем производные. Мы сначал считаем производные выхода модели по $h_1, h_2$, зная эти производные мы можем посчитать производные по параметра. Зная производные $z_1, z_2$, мы можем посчитать производные по следующим параметрам.\n",
    "\n",
    "* Метод обратного распространения ошибки (backpropagation)\n",
    "\n",
    "Рассмотрим производные выхода модели по выходам всех нейронов. Если мы хотим посчитать производную по входу, Тогда у нас будет 3 пути из $x_1$ в выход и по ним мы суммируем все частные производные. Но для нас нет смысла считать производную по значению признака, так как нам необходимо считать производные по тем параметрам, которые мы будем изменять. Ну тогда производная по значению признака не нужна, так как мы не будем изменять значение признака.\n",
    "\n",
    "<img src='img/lecture02/13.png'>\n",
    "\n",
    "**Заметки по Backprop:**\n",
    "\n",
    "* Во многие формулы входят одни и те же производные\n",
    "\n",
    "* В backprop каждая частная производная вычисляется один раз — вычисление производных по слою N сводится к перемножению матрицы производных по слою N+1 и некоторых векторов\n",
    "\n",
    "Чтобы посчитать производную по параметрам слоя - необходимо знать производные по всем следующим слоям. И если нам необходимо посчитать производные выхода модели по некоторому слою, тогда подсчет производных можно выразить как умножение матрицы произвдных выхода следующего слоя умноженное на некоторый вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd367ab",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">1 Обучение нейронных сетей</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f89ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
