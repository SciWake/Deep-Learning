{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb733aa8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Обратное распространение ошибки</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1 Обучение нейронных сетей</h1>\n",
    "\n",
    "* Все слои обычно дифференцируемы, поэтому можно посчитать производные по всем параметрам.\n",
    "\n",
    "<img src='img/lecture02/1.png'>\n",
    "\n",
    "* $\\large a(x) = \\text{FC}_2(f(\\text{FC}_1(x)))$\n",
    "\n",
    "Параметры содержатся внутри $\\text{FC}_1, \\text{FC}_2$, так как полносвязные слои это набор линейных моделей с некоторыми весами, которые необходимо обучить. Для обучения зписываем функционал ошибки и минимизируем его:\n",
    "\n",
    "$$\\large \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} L(y_i, a(x_i)) \\to \\underset{a}{\\text{min}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04103c76",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">2 Как считать производные?</h1>\n",
    "\n",
    "<img src='img/lecture02/2.png'>\n",
    "\n",
    "На вход подаются два признака $x_1, x_2$, мы видим три полносвязных слоя:\n",
    "\n",
    "* Первый полносвязный слой - с некоторыми весами суммируем входные признаки и получаем два выходных числа $z_1, z_2$.\n",
    "* Выходы первого слоя $z_1, z_2$ суммируем с некоторыми весами и получаем два выходных числа $h_1, h_2$.\n",
    "* После $h_1, h_2$ суммируем с некоторыми коэффициентами и получаем прогноз модели.\n",
    "\n",
    "### На примере\n",
    "\n",
    "Стоит заметить, что в нашем примере нет нелинейности, так как это усложняет подсчеты. Возьмем конкретные веса для нашей нейронной сети:\n",
    "\n",
    "<img src='img/lecture02/3.png'>\n",
    "\n",
    "Посчитаем для наших входов значение каждого узла:\n",
    "\n",
    "<img src='img/lecture02/4.png'>\n",
    "\n",
    "Что если мы изменим выделенный вес $1$? Прогноз модели не изменится, так как в 3 слое входное значение равено $0$. Производная это характеристика того, насколько будет изменятся функция если мы будем изменять вход. Производная по весу будет говорить о том, насколько сильно изменится прогноз модели, если мы изменим данный вес. В нашем случае, производная будет равняться нулю. Поэтому нам необходимо изменить другой вес, для второго слоя у нейрона изменим вес равный $0$ на $1$:\n",
    "\n",
    "<img src='img/lecture02/5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264fdfd",
   "metadata": {},
   "source": [
    "## Общий вид\n",
    "\n",
    "### Производная по $p_{11}$\n",
    "\n",
    "$$\\large a(x) = p_{11} h_1(x) + p_{21} h_2(x)$$\n",
    "\n",
    "<img src='img/lecture02/6.png'>\n",
    "\n",
    "Продифференцируем выход модели $a$ по весу $p_{11}$\n",
    "\n",
    "$$\\large \\frac{\\partial a}{\\partial p_{11}} = h_1(x)$$\n",
    "\n",
    "* Чем больше $h_1(x)$, тем сильнее $p_{11}$ влияет на $a$\n",
    "\n",
    "### Производная по $v_{11}$\n",
    "\n",
    "В данном случае, вместо $h_{1}$ мы подставляем чему равняется $h_1$, где $h_1$ это некотороя нелинейность от суммы с некоторыми коэффициентами:\n",
    "\n",
    "$$\\large a(x) = p_{11} f(v_{11} z_1(x) + v_{21} z_2(x)) + p_{21} h_2(x)$$\n",
    "\n",
    "<img src='img/lecture02/7.png'>\n",
    "\n",
    "$$\\large \\frac{\\partial a}{\\partial v_{11}}  = \\frac{\\partial a}{\\partial h_{1}} \\frac{\\partial h_1}{\\partial v_{11}} = p_{11} \\cdot f^{'} z_{1}(x)$$\n",
    "\n",
    "Для нахождения производной модели по внутреннему весу, необходимо знать производную по более позднему слою."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c27e03",
   "metadata": {},
   "source": [
    "### Производная по $w_{11}$\n",
    "\n",
    "<img src='img/lecture02/8.png'>\n",
    "\n",
    "Как посчитать производную $a$ по $w_{11}$?\n",
    "\n",
    "$\\large \\frac{\\partial a}{\\partial w_{11}} = ?$\n",
    "\n",
    "Если мы запишем как зависит $a$ от $w_{11}$ и посчитаем производную, тогда это будет очень сложно. Воспользуемся другим подходом:\n",
    "\n",
    "* Как сильно изменяется $a$ при изменении $w_{11}$? Если мы будем изменять $v_{11}$, будет ли изменяться влияние на $w_{11}$ на выход? Конечно, так как $w_{11}$ влияет на $z_1$, а $z_{1}$ через $v_{11}$ влияет на выход.\n",
    "\n",
    "<img src='img/lecture02/9.png'>\n",
    "\n",
    "* Если мы будем изменять $v_{12}$, будет ли изменяться влияние на $w_{11}$ на выход? Будет, так как $w_{11}$ влияет на $z_1$, а $z_{1}$ через $v_{12}$ влияет на выход.\n",
    "\n",
    "<img src='img/lecture02/10.png'>\n",
    "\n",
    "* Если мы будем изменять $w_{22}$, будет ли изменяться влияние на $w_{11}$ на выход? Нет, так как $w_{11}$ влияет только $z_{1}$, то есть, $w_{22}$ не проходит через $w_{11}$.\n",
    "\n",
    "**Нахождение производной**\n",
    "\n",
    "<img src='img/lecture02/11.png'>\n",
    "\n",
    "Чтобы посчитать частную производную выхода по $w_{11}$, необходимо найти все пути, которые идут из $w_{11}$ в выход и просуммировать по каждому пути все частные производные:\n",
    "\n",
    "$$\\large \\frac{\\partial a}{\\partial w_{11}}  = \\frac{\\partial a}{\\partial h_{1}} \\frac{\\partial h_1}{\\partial z_{1}} \\frac{\\partial z_1}{\\partial w_{11}} +\\frac{\\partial a}{\\partial h_{2}} \\frac{\\partial h_2}{\\partial z_{1}} \\frac{\\partial z_1}{\\partial w_{11}}$$\n",
    "\n",
    "Так как $w_{11}$ влияет на $a$ через два пути, поэтому у нас два слогаемых. Вдоль каждого пути суммируем значения частных производных, производная $a$ по $h_{1}$, производная $h_1$ по $z_{1}$, производная $z_1$ по $w_{11}$ + ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b8fdf",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">2.1 Метод обратного распространения ошибки</h2>\n",
    "\n",
    "Делаем вывод, чтобы посчитать производную по параметрам некоторого слоя, необходимо знать производные по параметрам более поздних слоев.\n",
    "\n",
    "<img src='img/lecture02/12.png'>\n",
    "\n",
    "* Мы как бы идём в обратную сторону по графу и считаем производные. Мы сначал считаем производные выхода модели по $h_1, h_2$, зная эти производные мы можем посчитать производные по параметра. Зная производные $z_1, z_2$, мы можем посчитать производные по следующим параметрам.\n",
    "\n",
    "* Метод обратного распространения ошибки (backpropagation)\n",
    "\n",
    "Рассмотрим производные выхода модели по выходам всех нейронов. Если мы хотим посчитать производную по входу, Тогда у нас будет 4 пути из $x_1$ в выход и по ним мы суммируем все частные производные. Но для нас нет смысла считать производную по значению признака, так как нам необходимо считать производные по тем параметрам, которые мы будем изменять. Ну тогда производная по значению признака не нужна, так как мы не будем изменять значение признака.\n",
    "\n",
    "<img src='img/lecture02/13.png'>\n",
    "\n",
    "**Заметки по Backprop:**\n",
    "\n",
    "* Во многие формулы входят одни и те же производные\n",
    "\n",
    "* В backprop каждая частная производная вычисляется один раз — вычисление производных по слою N сводится к перемножению матрицы производных по слою N+1 и некоторых векторов\n",
    "\n",
    "Чтобы посчитать производную по параметрам слоя - необходимо знать производные по всем следующим слоям. И если нам необходимо посчитать производные выхода модели по некоторому слою, тогда подсчет производных можно выразить как умножение матрицы произвдных выхода следующего слоя умноженное на некоторый вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed950170",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Полносвязные сети для изображений</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1 Принцып работы</h1>\n",
    "\n",
    "Имеется рукопистный набор данных MNIST:\n",
    "\n",
    "* Изображения 28 x 28\n",
    "* Изображения центрированы\n",
    "* 60.000 объектов в обучающей выборке\n",
    "\n",
    "На вход нейронной сети будет подаваться картинка размером $28 x 28$ пикселей, значит всего 784 пикселя и запишим их как один вектор и будем подавать на вход нейронной сети. \n",
    " \n",
    "В первом полносвязном слоее мы имеем 10 нейронов, каждый нейрон - это сумма входных пикселей с некоторыми весами и получаем 10 новых чисел (нейронов). Дальше во втором полносвязном слое будет 10 нейронов и каждый отвечает за свой класс и дальше мы смотрим, в каком выходном слоее смотрим в каком нейроне получилось наибольшее число и делам вывод о том, какая цифра находится на картинке.\n",
    "\n",
    "<img src='img/lecture02/14.png'>\n",
    "\n",
    "И какой смысл получается у каждого нейрона? Нейрон суммирует с некоторыми весами все входные пиксили. Например, первый нейрон будет суммировать некотрые пиксили с нулевыми весами, так как некоторая область на картинке будет постоянно пустой - это те области, где ни разу не встречались черные пиксели для некоторой цифры. Соответсвенно, каждый нейрон может детектировать заполненность конкретного набора пикселей. После мы можем скомбинировать эти знания в следующем слоее и получим некоторый результат.\n",
    "\n",
    "### Проблема \n",
    "\n",
    "Мы можем научиться нейронами детектировать заполненность конкретных областей, но если мы детектируем 1, как заполненность области по центру, тогда что будет если мы напишем еденицу где-то сбоку? Тогда нейронная не сможет понять что это 1, так как мы детектируем черные пиксили по центру. То есть, если мы применяем полносвязные нейронные сети, тогда они будут выучить конкретное расположение объектов на картинке.\n",
    "\n",
    "* Если немного сдвинуть цифру, то нейрон уже не будет на неё реагировать.\n",
    "\n",
    "Подбробнее: https://srome.github.io/Jitter,-Convolutional-Neural-Networks,-and-a-Kaggle-Framework/\n",
    "\n",
    "### Число параметров\n",
    "\n",
    "* Если у нас 784 входа\n",
    "* Полносвязный слой: 1000 нейронов\n",
    "* Выходной слой: 10 нейронов (по одному на каждый класс)\n",
    "* Весов между входным и полносвязным слоями: (784 + 1)*1000 = 785.000 параметров\n",
    "* Весов между полносвязным и выходным слоями: (1000 + 1) * 10 = 10.010 параметров\n",
    "\n",
    "И как мы знаем, что если параметров больше чем данных - то это плохо.\n",
    "\n",
    "### Выводы\n",
    "\n",
    "Использование полносвязных нейронных сетей для работы с картинками является плохой идей так как:\n",
    "\n",
    "* Очень много параметров\n",
    "* Легко могут переобучиться\n",
    "* Не учитывают специфику изображений (сдвиги, небольшие изменения формы и т.д.)\n",
    "* Один из лучших способов борьбы с переобучением — снижение числа параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a5018",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Свёрточные сети</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1 Свертки</h1>\n",
    "\n",
    "Эксперименты со зрительной корой https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1557912/\n",
    "\n",
    "<h2 style=\"color:#008B8B\">1.1 Процесс свертки</h2>\n",
    "\n",
    "**Шаг 1.**\n",
    "\n",
    "На входе имеется картинка размером 4х4 пикселя. Ещё у нас имеется некоторый фильтр (ядро свертки) - это некоторая картинка, но меньшего размера 2х2 пикслеля. Что такое свертка? Мы берем первый блок из основной картинки такого же размера как фильтр и умножаем его покоординатно на фильтр и суммируем что получилось.\n",
    "\n",
    "<img src='img/lecture02/15.png'>\n",
    "\n",
    "**Шаг 2.**\n",
    "\n",
    "Дальше берем следующий блок и так по всем блокам... Это и есть операция свертки. Фильтр мы будем обучать методом градиентного спуска. Фильтр одинаковый для всех частей картинки.\n",
    "\n",
    "<img src='img/lecture02/16.png'>\n",
    "\n",
    "Данную операцию можно применять для любых матриц и соответственно фильтр тоже может быть любого размера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163ccca",
   "metadata": {},
   "source": [
    "### Смысл свертки\n",
    "\n",
    "Рассмотрим следующий фильтр. На главной диогонали расположены еденицы, а на побочной нули. Посмотрим как откликается фильтр на определенные картинки. Ну и ниже мы видим отклик 2, 2, 1, 0, 6, 10:\n",
    "\n",
    "<img src='img/lecture02/17.png'>\n",
    "\n",
    "Что это значит? Фильтр задает некоторый паттерн - что-то на диагонали, в нашем случае это черные пиксели. На первых двух откликах фильтра у нас действительно стоят 1 на диагонали. На отклике с выходом 1, черные пиксели стоят не везеде, а для отклика с ответом 0 черных пикселей вообще нет. Тем самым, отклик фильтра говорит о том, насколько паттерн присутствует на данному кусочке изображения.\n",
    "\n",
    "* Операция свёртки выявляет наличие на изображении паттерна, который задаётся фильтром\n",
    "\n",
    "* Чем сильнее на участке изображения представлен паттерн, тем больше будет значение свёртки\n",
    "\n",
    "Статья о свертках: https://arxiv.org/pdf/1603.07285.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561747db",
   "metadata": {},
   "source": [
    "### Максимум свёртки инвариантен к сдвигам\n",
    "\n",
    "Если нас интересует вопрос, имеется ли на картинке где-то данный паттерн с диагональю. Имеется две картинки, на одной диагональ расположена в нижнем углу, а на второй в левом верхнем углу.\n",
    "\n",
    "<img src='img/lecture02/18.png'>\n",
    "\n",
    "Применив свертку мы получим некоторый результат, после возьмем максимум  этого результата и на двух картинках максимум равен 2. Если посмотреть, есть ли где-то 2, тогда мы проверим наличие паттерна (диагональной линии). Это дает следующую идею, если мы захочем детектировать наличие еденицы, тогда возьмем некоторый фильтр, который определяет наличие еденицы под углом, после сделаем свертку и если у фильтра будет большой отклик, значит на картинке скорее всего есть еденица. Так как еденица может быть написана в разынх формах, тогда нам может понадобиться много разных фильтров.\n",
    "\n",
    "Значит, мы сможем находить, например еденицу, независимо от того, где она расположена, это хорошо демонстрирует пример выше, где мы взяли максимум двух сверток."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf602bc0",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">1.2 Свертки в компьютерном зрении</h2>\n",
    "\n",
    "\n",
    "**Пример 1**\n",
    "\n",
    "Ещё до появления нейронных сетей придумали, что использование фильтров это полезно. Например давно существует фильтр собеля, который позволяет находить горизонтальные переходы:\n",
    "\n",
    "<img src='img/lecture02/19.png'>\n",
    "\n",
    "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1\n",
    "\n",
    "**Пример 2**\n",
    "\n",
    "Существует фильтр, который выполняет повышение резкости\n",
    "\n",
    "<img src='img/lecture02/20.png'>\n",
    "\n",
    "https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html\n",
    "\n",
    "**Пример 3**\n",
    "\n",
    "Фильтр размытие\n",
    "\n",
    "<img src='img/lecture02/21.png'>\n",
    "\n",
    "https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html\n",
    "\n",
    "А мы обсудим то, как фильтры автоматически подбирать под данные и объеденять в нейросетевые архитектуры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0572127",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">1.3 Формула свертки</h2>\n",
    "\n",
    "$$\\large \\text{im}^{\\text{out}}(x, y) = \\sum\\limits_{i=-d}^{d} \\sum\\limits_{j=-d}^{d} K(i, j) \\text{im}^{\\text{in}}(x + i, y + j)$$\n",
    "\n",
    "$\\text{im}^{\\text{out}}$ - пиксель с координатами $x, y$ выходного изображения.\n",
    "\n",
    "$\\text{im}^{\\text{in}}$ - входное изображение\n",
    "\n",
    "Картинка является двумерной, где в каждой ячейке расположен некоторый пиксель, который имеет определенный цвет.\n",
    "\n",
    "Имеется фильр размера \"2d + 1 на 2d + 1\" и будем нумеровать строчки и столбцы - не от еденицы до \"2d + 1\", а от $-d$ до $d$ $(-d, -d + 1, \\ldots 0, \\ldots, d - 1, d)$. Дальше мы суммируем по всем координатам фильтра, по оси $x, y$, где $i$ это номер координаты по $x$, а $j$ номер координаты по $y$.\n",
    "\n",
    "Как мы вычисляем пиксель в выходном изображении с координатами $x, y$? Для этого необходимо взять пиксель входного изображения с координатами $x, y$ и распологаем фильтр так, чтобы пиксель с координатами  $x, y$ распологался по центру.\n",
    "\n",
    "Дальше мы записываем сумму по $i$ от $-d$ до $d$, по $j$ от $-d$ до $d$, берем пиксель от входного изображения с координатами $(x + i, y + j)$. Если $i = -d, j = -d$, тогда это будет пиксель, который расположен в крайнем левом углу фильтра. После, пиксель от входного изображения с координатами $(x + i, y + j)$ и умножаем на соответствующий номер в фильтре $K(i, j)$. И так мы проходимся по всему квадрату, который мы расположили относительно пикселя из входного изображения.\n",
    "\n",
    "**Замечания:**\n",
    "\n",
    "* В качестве центра мы не можем взять боковые пиксели, поэтому итоговое изображение будет иметь меньший размер.\n",
    "\n",
    "* Если фильтр будет прямоугольным, тогда формула будет принимать другой вид, сейчас нам это не требуется.\n",
    "\n",
    "**Особенности свертки или же свойства:**\n",
    "\n",
    "* Пиксель в результирующем изображении зависит только от небольшого участка исходного изображения (local connectivity), размер которого определяет фильтр. Это отличает свертку от полносвязного слоя, где каждый выход полносвязного слоя зависит от каждого входа. Тем самым, мы можем сильно сократить число параметров, так как нет необходимости изучать с которым каждый входной пиксель влияет на выбранный выходной пиксель. Так если выходной пиксель зависит от 9 пикселей входного изображения, тогда нет смысла учитывать остальные пиксели входного изображения.\n",
    "\n",
    "* Веса одни и те же для всех пикселей результирующего изображения (shared weights). Если мы возьмем несколько выходных пикселей, которые зависят от небольшой области входного изображения, каждый выходной пиксель зависит от некоторой области входного изображения, но с одними и теми же весами, так как фильтр не изменяется. А в полносвязном слое, каждый выход зависит от всех входов и ещё всюду разные веса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02102e81",
   "metadata": {},
   "source": [
    "### Учет цвета в формле\n",
    "\n",
    "* Обычно исходное изображение цветное!\n",
    "* Это означает, что в нём несколько каналов (R, G, B). Значит мы можем кодировать каждый пиксель тремя числами, количество красного, синего, зеленого.\n",
    "\n",
    "Тогда в входном изображении появляется третья координата - канал. Тем самым каждая картинка представляет собой тензор. Где на первом слое изображения записана красная политра цвета, на втором слое зеленая политра, на третьем слое синяя политра цвета.\n",
    "\n",
    "$$\\large \\text{im}^{\\text{out}}(x, y) = \\sum\\limits_{i=-d}^{d} \\sum\\limits_{j=-d}^{d} \\sum\\limits_{с=1}^{С} K(i, j, c) \\text{im}^{\\text{in}}(x + i, y + j, c)$$\n",
    "\n",
    "Так как картинка становится трехмерной, добавляется ещё сумма по каналам изображения и фильтор тоже становится трехмерным. Тогда мы будем учитывать цвет пикселя. \n",
    "\n",
    "**Почему выходной пиксель без учета параметра с?** Так как мы сворачиваем цветовы каналы. Для выходного изображения с координатами $(x, y)$ мы суммируем каждый канал входного пикселя $(x, y)$ с значением нашего фильтра. \n",
    "\n",
    "<img src='img/lecture02/22.png'>\n",
    "\n",
    "Как видим, выходная картинка одномерная."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61664585",
   "metadata": {},
   "source": [
    "### Добавление нескольких фильтров\n",
    "\n",
    "Так как один фильтр находит конкретный паттерн на изображении. Но нам необходимо решать более сложные задачи, тогда использование одного фильра не даст хорошего результата и поэтому необходимо использовать несколько фильтров.\n",
    "\n",
    "* Одна свёртка выделяет конкретный паттерн на изображении\n",
    "* Нам интересно искать много паттернов\n",
    "* Сделаем результат трёхмерным:\n",
    "\n",
    "$$\\large \\text{im}^{\\text{out}}(x, y, t) = \\sum\\limits_{i=-d}^{d} \\sum\\limits_{j=-d}^{d} \\sum\\limits_{с=1}^{С} K_{t}(i, j, c) \\text{im}^{\\text{in}}(x + i, y + j, c)$$\n",
    "\n",
    "Тем самым, из входного изображения размером $H \\times W \\times C$ мы будем получать выходное изображение размера $H \\times W \\times T$. На выходе мы получаем тензор, то есть много картинок, где каждая картинка это результат свертки с некоторым фильтром.\n",
    "\n",
    "#### Число параметров\n",
    "\n",
    "* Обучается только фильтр\n",
    "\n",
    "* Параметры имеются у фильтров $K_{t}(i, j, c)$, где количество фильтров $T$, количество каналов у изображения составит $C$ и число пикселей вычисляется как $(2d + 1) \\cdot (2d + 1) =(2d + 1)^2$. Тогда $(2d + 1)^2 \\cdot C \\cdot T$ обучаемых параметров будет в сверточном слое."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d065c25",
   "metadata": {},
   "source": [
    "**Реализация в PyTorch**\n",
    "\n",
    "Зачастую, ещё добавляют сдвиг $b_t$, по аналогии с линейными моделями. Это можно интерпертировать как умножение кусочка изображения $\\text{im}^{\\text{in}}(x + i, y + j, c)$ с некоторыми весами $K_{t}(i, j, c)$, но так как в линейных моделях имеется сдвиг, то добавим его $b_t$. Особого физического смысла это не несет.\n",
    "\n",
    "$$\\large \\text{im}^{\\text{out}}(x, y, t) = \\sum\\limits_{i=-d}^{d} \\sum\\limits_{j=-d}^{d} \\sum\\limits_{с=1}^{С} K_{t}(i, j, c) \\text{im}^{\\text{in}}(x + i, y + j, c) + b_t$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
