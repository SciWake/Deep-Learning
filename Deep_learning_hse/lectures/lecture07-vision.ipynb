{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab71f9cf",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Интерпретация моделей</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1. Что находят свёрточные сети?</h1>\n",
    "\n",
    "https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf\n",
    "\n",
    "* Можно для каждого фильтра найти кусочки картинок, дающие самый сильный отклик\n",
    "* Сделаем это для AlexNet\n",
    "\n",
    "Можно среди всей обучающей выборки найти картинку и кусочек на ней, где фильтр дает наибольший отклик. Посомтрим на пример 3-го сверточного слоя:\n",
    "\n",
    "<img src='img/lecture07/1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5f555",
   "metadata": {},
   "source": [
    "## Максимизация вероятности класса\n",
    "\n",
    "### Вариант 1\n",
    "\n",
    "https://arxiv.org/pdf/1312.6034.pdf\n",
    "\n",
    "Возьмем обученную нейронную сеть $a_y(x)$, где $y$ - это выход конкретного класса, например, вероятность того, что это кошка. Дальше подаем на вход случайную картинку $x$, после чего начинаем изменять данную картинку градиентным спуском, чтобы максимизировать вероятность того, что на картинке кошка. Мы же можем градиентным спуском обучать не параметры, а саму картинку. Тогда посчитам backprop выходы сетки по пикселям входной картинки, после чего сдвигать пиксели, чтобы вероятность максимизировалась.\n",
    "\n",
    "Так же, имеется регуляризатор, который ограничивает величины интенсивности цветов, которые записаны в пикселях.\n",
    "\n",
    "$\\large a_y(x) - \\lambda \\|x\\|_2^2 \\to \\underset{x}{\\text{min}}$\n",
    "\n",
    "Посмотрим, какие картинки с точки зрения нейронной сети с большей вероятностью содержат тот или иной класс:\n",
    "\n",
    "<img src='img/lecture07/2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf8299",
   "metadata": {},
   "source": [
    "### Вариант 2\n",
    "\n",
    "Здесь улучшенная версия\n",
    "\n",
    "https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html\n",
    "\n",
    "<img src='img/lecture07/3.png'>\n",
    "\n",
    "Давайте теперь инициализировть вход не случайным шумом, как это было на прошлых картинках, а возьмем за основу некоторую картинку и будем максимизировать вероятность некоторого класса.\n",
    "\n",
    "<img src='img/lecture07/4.png'>\n",
    "\n",
    "Дальше можно взять большие картинки и максимизировать вероятность некоторого класса.\n",
    "\n",
    "<img src='img/lecture07/5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2c345",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Компьютерное зрение</h1>\n",
    "\n",
    "Мы научились выполнять классификацию изображений с использованием нейронных сетей.\n",
    "\n",
    "<img src='img/lecture07/6.png'>\n",
    "\n",
    "**Зачастую, хочется решать другие задачи:**\n",
    "\n",
    "* Semantic Segmentation - какой пиксель картинки относится к какому классу. Желтый пиксел - это класс кот, фиоллетовый пиксель - это лес...\n",
    "\n",
    "* Object detection - не просто говорим что собака находится на изображении, а говорим где она находится, выделив их прямоугольниками.\n",
    "\n",
    "* Instanct Segmentation - в этом примере мы выделяем область на картинге, где имеется собака."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd50f2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">2. Семантическая сегментация</h1>\n",
    "\n",
    "Все задачи выше мы будем сводить к классификации, так как мы уже умеем решать данную задачу.\n",
    "\n",
    "<img src='img/lecture07/7.png'>\n",
    "\n",
    "В этой задаче необходимо для каждого пикселя картинки сказать, к какому классу этот пиксель относится.\n",
    "\n",
    "## Постановка задачи\n",
    "\n",
    "* Данные: изображения и их корректные сегментации\n",
    "* Пример: PASCAL VOC 2012\n",
    "\n",
    "Изначально, необходимо разобраться как устроены данные.\n",
    "\n",
    "<img src='img/lecture07/11.png'>\n",
    "\n",
    "Как видим, у нас имеется весьма мало объектов внутри классов, как мы будем это обучать на таком маленьком наборе данных? Поскольку каждая картинка несет в себе дополнительную информацию, так как класс известен для каждого пикслея. В случае, если у нас $1500$ картинок размером $100 \\times 100$, тогда всего пикселей, для которых известны классы $15,000, 000$. \n",
    "\n",
    "Следовательно, в случае сегментации мы можем работать с очень маленькими выбороками, так как мы решаем задачу классификации не картинок, а классификации каждого пикселя.\n",
    "\n",
    "* Каждый объект содержит сильно больше информации, чем при\n",
    "классификации!\n",
    "* Можно хорошо обучаться на небольших выборках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11713e",
   "metadata": {},
   "source": [
    "## Метрики качества\n",
    "\n",
    "### Попиксельная доля верных ответов:\n",
    "\n",
    "$$\\large L(y, a) = \\frac{1}{n} \\sum\\limits_{i=1}^n [y_i = a_i]$$\n",
    "\n",
    "Где $n$ - число пикселей в картинке. $y_i$ правильный класс для $i$-го пикслея, $a_i$ класс, который выдала модель для $i$-го пикселя.\n",
    "\n",
    "Суммируем по всем пикселям и смотрим долю пикселей где модель угадала правильный класс. Обучаться модель будет на другой функционал, так как данный функционал не дифференцируемый.\n",
    "\n",
    "### Мера Жаккара (считается отдельно для каждого класса):\n",
    "\n",
    "Если почти всю картинку занимает автобус, но модель захватила весь автобус и несколько областей рядом. Скорее всего в этом нет ничего страшного, так как автобус был найден и мы не хотим штрафовать модель за небольшие отклонения от правильного сегмента. Для этого используется Мера Жаккара (IoU): \n",
    "\n",
    "$$\\large J_k (y, a) = \\frac{\\sum_{i=1}^n [y_i = k] [a_i = k]}{\\sum_{i=1}^n \\text{max}([y_i = k], [a_i = k])}$$\n",
    "\n",
    "\n",
    "Мера Жаккара считается для каждого класса в отдельности. Например, мы взяли калсс автобус и проходимся по всем пикселям. В числителе считаем число пикселей, которые должны относиться к автобусу и модель отнесла их к автобусу. В знаменателе считаем число пикселей, которые на самом деле относятся к автобусу или модель отнесла к автобусу.\n",
    "\n",
    "Другими словами, мы берем две области. Первая область, где модель отнесла к автобусу и где нас самом деле находится автобус. В числителе мы считаем площадь пересечения двух областей и делим на площадь объеденения двух областей. Можно посчитать меру Жаккара для каждого класса и усреднить по всем классам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317dd35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a05afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
