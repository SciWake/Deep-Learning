{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0de2a6b",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Архитектуры свёрточных сетей</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1. LeNet (1998)</h1>\n",
    "\n",
    "<img src='img/lecture03/14.png'>\n",
    "\n",
    "### Принцип архитектуры следующий:\n",
    "\n",
    "* На вход подается черно-белая картинка (один канал) размером $32 \\times 32$\n",
    "* Применение свертки (Convolutions) на выходе с 6-ю каналами/фильтрами.\n",
    "* Использование Subsampling (Pooling).\n",
    "* Применение свертки Convolutions на выходе с 16 каналами.\n",
    "* Использование Subsampling (Pooling), после применения которого получаем 16 фильтров размером 5 на 5.\n",
    "* Производим вытягивание в вектор.\n",
    "* Использование трех полносвязных слоев - первый, второй и выходной слой.\n",
    "\n",
    "Изначально мы применяем свертки несколько раз, что логично, так как свертки выделяют некоторые паттерны на картинках. Обычно, выходом свертки является трехмерный массив, где два измерения это размерности картинки, а третье измерение прдеставляет собой разные каналы. Ну и в каждом канале содержится свой некоторый паттерн.\n",
    "\n",
    "**Вопросы:**\n",
    "\n",
    "1) Как 6 перешло в 16? Имеется 6 каналов или же 6 картинок размером 14 на 14. Мы можем рассматривать эти 6 каналов как трехмерную таблицу. Берем первый фильтр, например $3 \\times 3 \\times 6$ и проходя по всей 3-х мерной таблице, сварачиваем с некоторым фильтром, получаем первую свертку. Берем втрой фильтр $3 \\times 3 \\times 6$, но с другими числами, проходимся по всей таблице и получаем вторую свертку... Так можно сделать любое количество фильтров, в данном примере взяли 16 фильтров.\n",
    "\n",
    "2) Что такое Subsampling? Мы называли это MaxPooling.\n",
    "\n",
    "3) Почему при использованнии трехмерного фильтра на выходе получается матрица? Когда фильтр трехмерный, например 3 на 3 и третья его размерность равна количеству каналов в исходном изображении. В нашем примере мы брали третью размерность равную 6. Следовательно, наш фильтр заполняет всю третью размерность и мы не можем его передвигать, а вот по двумерному простраству $x$ и $y$ мы можем премещаться, следовательно на выходе получается матрица.\n",
    "\n",
    "Мое предположение: Мы можем рассматривать свертку такой трехмерной таблицы как применение шести фильтов, которые суммируются в одную итоговую свернутую картинку.\n",
    "\n",
    "### Особенности LeNet \n",
    "\n",
    "* Для данных MNIST\n",
    "* Идея end-to-end обучения\n",
    "* Использовали аугментацию\n",
    "* Около 60.000 параметров\n",
    "* Доля ошибок на тесте 0.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec143f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">2. ImageNet (2010)</h1>\n",
    "\n",
    "* Соревнование: ImageNet Large Scale Visual Recognition Challenge (ILSVRC)\n",
    "* Около 1.000.000 изображений\n",
    "* 1000 классов\n",
    "* Обычно качество измерялось на основе лучшей гипотезы модели. Качество измерялось как top-r accuracy - берем 5 классов, которые с наибольшей вероятностью относятся к данной картинке и смотрим есть ли среди этих топ 5 классов хотябы один правильный. Известно, что разметка не очень хорошая, так как люди могли не заметить некоторые классы на картинке. Следовательно, если модель нашла дерево, а разметчик его не отметил, тогда мы не будем штрафовать за это, а просто среди топ 5 найдем хоть один правльный класс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6d9c8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">3. AlexNet (2012)</h1>\n",
    "\n",
    "В 2012 произошёл прорыв, вышла статья ImageNet Classification with Deep Convolutional Neural Networks:\n",
    "\n",
    "https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "\n",
    "<img src='img/lecture03/15.png'>\n",
    "\n",
    "### Принцип архитектуры следующий:\n",
    "Можем наблюдать, что архитектура нейронной сети состоит из двух одинаковых частей. Это было сделалано для того, чтобы модель можно было разделить между двумя видеокартами.\n",
    "\n",
    "* Первый слой - Применение свертки 11 на 11 со Stride 4. На выходе получаем 48 каналов.\n",
    "* Использование Max Pooling.\n",
    "* Применение свертки 5 на 5. На выходе имеем 128 каналов.\n",
    "* Использование Max Pooling\n",
    "* И так несколько раз\n",
    "* Вытягивание в вектор dense\n",
    "* Использование трех полносвязных слоев\n",
    "\n",
    "### Особенности AlexNet\n",
    "\n",
    "* Используют ReLU, аугментацию, dropout\n",
    "* Градиентный спуск с инерцией (momentum)\n",
    "* Обучение на двух GPU (5-6 суток)\n",
    "* Около 60 миллионов параметров\n",
    "* Ошибка около 17%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196d010",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">3. VGG (2014)</h1>\n",
    "\n",
    "Вышла следующая работа: VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION, где ещё сильнее улучшили качество моделей.\n",
    "\n",
    "https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "Насколько мы помним, в AlexNet свертки были уже достаточно большими, из-за чего было достаточно много парамтеров. Следовательно, тяжело сделать большое количество слоев, так как число параметров вырастет ещё сильнее и данных можен не хватать.\n",
    "\n",
    "### Принцип архитектуры следующий:\n",
    "\n",
    "В этой архитектуре исользовали все свертки размером 3 на 3. Но, зачест того, что свертки небольшого размра, параметров у нейронной сети немного, следовательно можно делать большее количество слоев. Было предложено  6 архитектур:\n",
    "\n",
    "<img src='img/lecture06/1.png'>\n",
    "\n",
    "**Рассмотрим архитектуру D.** \n",
    "\n",
    "* На вход поступает картинка $224 \\times 224$ RGB.\n",
    "* Два сверточных слоя, с размером фильра 3 на 3 и числом каналов с прошлого слоя. На выходе получаем 64 карты или же различных картинок, к которым опять применяется сверка 3 на 3 и числом каналов прошлого слоя (64) с выходом в 64 карты.\n",
    "* Max Polling.\n",
    "* Два сверточных слоя.\n",
    "* Max Polling.\n",
    "* И так несколько раз.\n",
    "* После всего, выполняем вытягивание и три полносвязных слоя. Где первые два полносвязных слоя имеют 4096 нейронов, а последний имеет 1000 нейроннов + softmax, так как всего 1000 классов.\n",
    "\n",
    "**Заметки:**\n",
    "\n",
    "Важно, что нелинейности используются, например, после сверточных слоев, полносвязных слоев, это мы не обговариваем, но подразумеваем использование нелинейностей.\n",
    "\n",
    "Стоит заметить, что несколько полносвязных слоев подряд не имеют смысла. А вот если использовать несколько сверток подряд, тогда как минимум поле восприятия будет увеличиваться. Но если необходимо, чтобы свертки выучивали более сложные не линейные закономерности, тогда необходимо добавлять нелинейности.\n",
    "\n",
    "Conv1-xx - это локально полносвязный слой. Берем одну пространнственную позицию всех каналов и сварачиваем водль всех каналов. Здесь не учитывается пространственная позиция, берется одна точка и с некоторым коэффициентом суммируем все пиксели по всем каналам.\n",
    "\n",
    "### Особенности VGG\n",
    "\n",
    "* Только маленькие свёртки. Почему использовали небольшие свертки? Позволяет сделать меньше параметров и засчет этого можно сделать больше сверточных слоев. А так как сверточных слоев становится больше, тогда и нелинейностей становится тоже больше, так после каждого полносвязного слоя применяются нелинейность.\n",
    "* Градиентный спуск с инерцией.\n",
    "* Dropout для двух первых полносвязных слоёв.\n",
    "* Хитрая инициализация (сначала обучается вариант A со случайными начальными весами, потом им инициализируются более глубокие сети).\n",
    "\n",
    "**Рассмотрим подробнее последний пункт:** Было предложено несколько архитектур, так как вариант E было невероятно сложно обучить с нуля:\n",
    "\n",
    "* Изначально обучали вариант A.\n",
    "* Весами из варианта A инициализировали веса в варианте B. Посмотрим на таблицу, жирным шрифтом выделены слои, которые являются новыми и их инициализировали случайно. Все остальное инициализировали тем, что обучилось в варинте A. Следовательно, мы просто дообучали модель и снуля необходимо обучить всего два слоя.\n",
    "* Переходим к варианту C, добавляется три слоя - обучаем их.\n",
    "* И так делаем переходы к следующим архитектурами.\n",
    "\n",
    "Заморозка прошлых слоев не использовалась, конечно, эти слои тоже дообучались, но благодаря хорошей инициализации не выделенных жирным слоев, эти слои не требовали серьёзных усилий.\n",
    "\n",
    "\n",
    "### Результаты VGG\n",
    "\n",
    "Посмотрим на последний столбец, ошибка составила уже 8%:\n",
    "\n",
    "<img src='img/lecture06/2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea89f7",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">4. GoogLeNet (2014)</h1>\n",
    "\n",
    "Going Deeper with Convolutions: https://arxiv.org/abs/1409.4842\n",
    "\n",
    "Слева вход, справа выходы. Основные особенности заключатся в том, что у данной неронной сети несколько выходов. Используем некоторые слои, потом используем выходы проомежуточного слоя, навешиваем два полносвзяных слоя и получаем выход. После выполняем подобное в других слоях:\n",
    "\n",
    "<img src='img/lecture06/3.png'>\n",
    "\n",
    "Для чего мы требуем чтобы в промежуточных слоях тоже хорошо предсказывались классы? Если в нейронной сети будет всего один выход, тогда при backpropagation градиенты идут с конца в начало. Следовательно, первые слои обучаются намного хуже, пока до них дйдет сигнал... Оказывается, что сеть обучается лучше, если добавить выходы на промежуточные слои, тогда при обучении градиенты будут исходить не только из конца нейронной сети, но и из дополнительных выходов.\n",
    "\n",
    "### Принцип архитектуры следующий:\n",
    "\n",
    "Во всех прошлых архитектурах была проблема. Если картинка содержит 192 канала и мы применяем к нему свертку, тогда свертка с фильтром 3 на 3 будет иметь размер $3 \\times 3 \\times 192$ и у такой свертки весьма много параметров. Хочется сокартить число параметров у каждой свертки, уменьшить количество каналов, конечно, большое количество каналов работает довльно хорошо, но тогда получается много параметров.\n",
    "\n",
    "<img src='img/lecture06/4.png'>\n",
    "\n",
    "**Projection layer:**\n",
    "\n",
    "Предположим, имеется тензор размером $24 \\times 24 \\times 192$, как видим, имеется много каналов. Применим к этому тензору свертки 1 на 1, которая выдает такую же картику размером $24 \\times 24 \\times 1$, в которой каждый элемент - это просуммирвоанные с некоторыми весами элементы всех каналов. Это напоминает метод главных компонент, где мы брали старые признаки и считали их линейные комбинации. Если мы правлиьно подбирали веса для линейных комбинаций, тогда получалось эффективно понижать размерность. В этом случае, свертка 1 на 1 делает подобное.\n",
    "\n",
    "Если мы выполним 30 сверток 1 на 1, тогда получится такая же картинка в которой не 192 канала, а 30 каналов. Поскольку мы обучаем веса с которыми сжимаем 192 канала в 30 каналов есть шанс того, что эти 30 каналов будут иметь такую же информативность. Один на однин свертки называют projection layer - проекционнный слой, слой понижения размерности, который сильно уменьшает количество каналов и после него канало становится меньше и в последующих свертках параметров будет тоже меньше.\n",
    "\n",
    "**Объяснение схемы:**\n",
    "\n",
    "* На вход приходит некий тензор Previous layer. Дальше выполняем параллельно 4 операции, рассмотрим их:\n",
    "\n",
    "* Применяем свертку 1 на 1 - получаем некоторый набор каналов.\n",
    "\n",
    "* Применяем свертки 1 на 1 после свертку 3 на 3. За счет того, что изначально понизили размерность, в свертке 3 на 3 будет меньше параметров.\n",
    "\n",
    "* Применяем свертки 1 на 1 после свертку 5 на 5.\n",
    "\n",
    "* Применяем 3 на 3 max pooling после свертку 1 на 1.\n",
    "\n",
    "* И все это 4 пути соединяем в один большой набор каналов (Filter concatenation) и получается выход данного блока - данный блок называется Inception.\n",
    "\n",
    "Параметры внутри операций блока подобраны так, чтобы на всех выходах получались карты одного размера для последующего соединения.\n",
    "\n",
    "### Особенности GoogLeNet\n",
    "\n",
    "* Снижается число каналов перед «тяжёлыми» свёртками\n",
    "* Несколько выходных слоёв для улучшения обучаемости\n",
    "* Обучается градиентным спуском с инерцией\n",
    "* Ошибка 6.67% на ImageNet\n",
    "\n",
    "До этого момента все ещё не было придуман batchnorm, именно поэтому в нейронной сети было несколько выходов. Выполняют 3 блока Inception, к нему добавляют пару полносвязных слоев и производят предсказание класса. После опять делают паур Inception блоков и к ним уже добавлют пару полносвязных слоев, выполняют предсказание и в конце полносвязные слои выполняют предсказания. Итоговое предсказание выполняется самым последним полносвязным слоем, но все остальные слои нужны только для распространения сигнала. Если же использовать batchnorm, тогда данная проблема уменьшается и дальше будут ещё трюки на эту тему."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d964e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">5. ResNet (2015)</h1>\n",
    "\n",
    "Deep Residual Learning for Image Recognition:\n",
    "\n",
    "https://arxiv.org/abs/1512.03385\n",
    "\n",
    "Рассмотрим классический варинат обучения нейронных сетей. Например, когда в VGG используем больше сверточных слоев. Берем нейронную сеть в 20 слоев и при обучении ошибка убывает. Но если взять 56 слоев, что почти в три раза больше, логично, что сеть должна как минимум переобучиться, так как параметров намного больше. Ошбика получается выше как на обучении, так и на тесте.\n",
    "\n",
    "<img src='img/lecture06/5.png'>\n",
    "\n",
    "Следовательно, у нас не получается обучить курпные нейронные сети. Мы не можем даже переобучить модель.\n",
    "\n",
    "* Добавление слоёв в свёрточную сеть ухудшает качество даже на обучении\n",
    "* Хотя возможностей для переобучения больше, сеть почему-то не может ими воспользоваться\n",
    "\n",
    "### Решение проблемы\n",
    "\n",
    "Возникло предположение, что если слоев много и при backpropagation градиенты по первым слоям практически не содержат информации о выходах.\n",
    "\n",
    "Имеется два слоя (weight layer), предлогается добавить между этими слоями residual connection - выход второго слоя будет устроенн как сумма выхода второго слоя $f(x)$ и того, что поступило на вход предыдущему слою $x$ или другими словами выход предпредыдущего слоя. Простым суммированием без различных весов:\n",
    "\n",
    "<img src='img/lecture06/6.png'>\n",
    "\n",
    "Следовательно информация от начала нейронной сети к концу может проходить не только через светочные, полносвязные слои, но и в обход их. На это можно посотреть так, пришедший входной сигнал может не проходя черезе некоторые преобразования пройти по residual connection до самого последнего слоя. Получается, что слои изучают не преобразования к входному сигналу, а учат добавки к входному сигналу. По умолчанию сигнал идет не измененный, а каждый слой может модифицировать сигнал через следующую сумму $f(x) + x$.\n",
    "\n",
    "\n",
    "### Принцип архитектуры следующий:\n",
    "\n",
    "**1) VGG-19** Взяли архитектуру VGG (нижняя картинка). Оставили количество пулингов такое же, где пулинг вставляются туда, когда изменяется цвет блока. Но межеду пулингами добавили ещё слоев.\n",
    "\n",
    "**2) 34-layer plain** \n",
    "\n",
    "* Блоки одного цвета это свертки с RELu друг за другом, в конце данного блока применятеся Max Pooling. \n",
    "\n",
    "* Снова идет следующий блок с сверточными слоями, после которого следует Max Pooling.\n",
    "\n",
    "* Ещё один такой блок.\n",
    "\n",
    "* И последний такой блок, который вытягивается и применение одного полносвязного слоя.\n",
    "\n",
    "**3) 34-layer residual** Информацию от входа прокидываем через слои постепенно, кроме max pooling, черз который мы не прокидываем выходы. Следовательно, то что поступило на вход, может без измений дойти до выхода.\n",
    "\n",
    "Почему стрелочка пунктиром? Так помечено выполнение residual connection через max pooling. Данная операция происходит иначе, так как размерность после max pooling изменяется. Это можно изучить дополнительно)\n",
    "\n",
    "<img src='img/lecture06/7.png'>\n",
    "\n",
    "### Особенности ResNet\n",
    "\n",
    "* Даёт низкую ошибку на обучении даже с 1000 слоёв, после добавили residual connection и она обучилась, следовательно, мы можем обучить огромную нейронную сеть. Но такая нейронная сеть выдает плохое качество на тестовой выборке, так как она переобучается.\n",
    "* Обучается градиентным спуском с инерцией со случайной инициализацией\n",
    "* Ошибка 4.49% на ImageNet\n",
    "\n",
    "<img src='img/lecture06/8.png'>\n",
    "\n",
    "На графике качество 3.57 получено ансамблирование моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6cafc",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">6. Xception</h1>\n",
    "\n",
    "Xception: Deep Learning with Depthwise Separable Convolutions:\n",
    "\n",
    "https://arxiv.org/abs/1610.02357\n",
    "\n",
    "<img src='img/lecture06/9.png'>\n",
    "\n",
    "\n",
    "### Особенности Xception\n",
    "\n",
    "* Разделяется роль свёрток: либо по каналам, либо по пространству\n",
    "* Более эффективное использование параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551ffbf",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">7. Что ещё?</h1>\n",
    "\n",
    "* Highway networks\n",
    "* Inception-ResNet\n",
    "* Squeeze and Excitation Network\n",
    "* MobileNet\n",
    "* EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a8ebd",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Архитектуры свёрточных сетей</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd3436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
