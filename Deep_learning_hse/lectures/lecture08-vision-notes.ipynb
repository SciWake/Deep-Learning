{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da0c33a",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Детекция объектов</h1>\n",
    "\n",
    "<!-- <h1 style=\"color:#008B8B\">1. Non-maximum supression</h1> -->\n",
    "\n",
    "## Non-maximum supression\n",
    "\n",
    "* Модель выдаёт для класса $k$ список прямоугольников с уверенностями\n",
    "* Проходим в порядке уменьшения уверенности\n",
    "* Для каждого прямоугольника удаляем все последующие, с которыми Intersection over Union (IoU) > 0.5\n",
    "\n",
    "Имеется $k$ классов и для каждого класса, модель выдаёт список прямоугольников с уверенностями. Возьмём первый прямоугольный (увверенность 0.9), из тех, которые модель выдала для первого класса. Среди всех следующих прямоугольников данного класса находим те, у которых (IoU) > 0.5. Переходим к следующему прямоугольники и повторяем операцию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e9fcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Метрики качества\n",
    "\n",
    "* Модель выдаёт для класса $k$ список прямоугольников с уверенностями\n",
    "* Считаем прямоугольник корректным, если $\\text{loU}(y,z) = \\text{Jaccard}(y, z) > t$\n",
    "* Строим PR-кривую, считаем под ней площадь, получаем Average Precision\n",
    "* Усредняем по всем классам, получаем mAP (mean AP)\n",
    "* Раньше $t = 0.5$, сейчас скорее $t = 0.75$\n",
    "\n",
    "Имеется размеченная картинка, модель расставила на данной картинке некоторые прямоугольники. Каждый из прямоугольников модели считаются корректными, если $\\text{loU}(y,z) = \\text{Jaccard}(y, z) > t$. Благодоря данному порогу мы определяем, правлиьный ли прямоугольник.\n",
    "\n",
    "Мы получили список прямоугольникоов, которые отсортированы по вероятностям принадлжености к некоторому классу. Дальше, проставляем метки правлиьности используя порог $t$ (loU) и считаем площадь под PR кривой. При построении PR кривой, мы сдвигаем порог, но используется порог на вероятности, которые выдает модель, а не loU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67304f17",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">1. Two-shot detection</h1>\n",
    "\n",
    "Будем решать задачу в два этапа:\n",
    "1. Находим «кандидатов» — прямоугольники, где скорее всего что-то есть\n",
    "2. Классифицируем эти прямоугольники\n",
    "\n",
    "## R-CNN\n",
    "\n",
    "1. Имеется входная картинка.\n",
    "2. Применяем, метод, которые формирует прямоугольники на картинке (~2000 штук). Берем каждый прямоугольник, выполняем преобразование его размера.\n",
    "3. Данный прямоугольник передаём предобученной неройнной сети (AlexNet...), из него достаём признаки с предпоследнего слоя.\n",
    "4. Используя данное признаковое описание обучаем классификатор (SVM...), который по данным признакм будет определять то, что находится в данном прямоугольнике.\n",
    "\n",
    "<img src='img/lecture08/1.png'>\n",
    "\n",
    "**Генерация кандидатов:**\n",
    "\n",
    "* «Внешние» методы из классического компьютерного зрения\n",
    "* Выбирается около 2000 прямоугольников\n",
    "\n",
    "Используем методы классического компьютерного зрения. Берём все пиксели, для каждого пикслея берём его признаки, координаты, цвета... и кластеризуем все пиксели. Один кластер называется суперпикселем. Выбираем прямоугольники так, чтобы они покрывали все спуерпиксели.\n",
    "\n",
    "<img src='img/lecture08/2.png'>\n",
    "\n",
    "Классификация прямоугольников:\n",
    "* SVM\n",
    "* One-vs-all\n",
    "\n",
    "### Проблемы:\n",
    "* Не end-to-end\n",
    "* Генерация кандидатов может быть очень сложной\n",
    "* Свёрточная сеть практически не настраивается под данные\n",
    "* Долго (много признаков, много классификаторов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8977a00",
   "metadata": {},
   "source": [
    "## Fast R-CNN\n",
    "\n",
    "Кандидаты всё ещё генерируются внешним методом. Но 3 и 4 шаг объеденили в один.\n",
    "\n",
    "<img src='img/lecture08/3.png'>\n",
    "\n",
    "* Для конкретного кандидата извлекаются признаки: вырезаются участки из последнего тензора, режутся на блоки, из каждого блока берётся максимум.\n",
    "\n",
    "### Скорость\n",
    "\n",
    "<img src='img/lecture08/6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed939def",
   "metadata": {},
   "source": [
    "## Faster R-CNN\n",
    "\n",
    "<img src='img/lecture08/7.png'>\n",
    "\n",
    "### Скорость\n",
    "\n",
    "<img src='img/lecture08/9.png'>\n",
    "\n",
    "<img src='img/lecture08/10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee06e2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">2. One-shot detection</h1>\n",
    "\n",
    "* Двухэтапные детекторы работают хорошо, но не очень быстро\n",
    "* Попытаемся одновременно и искать кандидатов, и определять их классы\n",
    "\n",
    "## YOLO\n",
    "\n",
    "1. Имеется входная картинка, которая разбита на S*S блоков;\n",
    "\n",
    "2. Пропускаем через сверточную архитектуру нейронной сети DarkNet (ResNet), берем последний свёрточный слой архитектуры $7 \\times 7 \\times 1024$;\n",
    "\n",
    "3. Применяем несколько полносвязынх слоёв, таких, что для каждой ячейки, полносвязный слой возвращает B характеристик прямоугольников (описаны в скобках и ниже) и вероятности конкретных классов при условии, что в данном прямоугольнике, что в прямоугольнике имеется объект;\n",
    "\n",
    "<img src='img/lecture08/11.png'>\n",
    "\n",
    "\n",
    "### Идея\n",
    "\n",
    "* Разбиваем изображение на $S\\times S$ блоков;\n",
    "* Для каждого блока предсказываем $B$ прямоугольников, это число фиксировано. Для каждого прямоугольника имеется:\n",
    "    * Координаты центра прямоугольника $(x, y)$, ширина и высота этого прямогульника. Таких прямоугольников один блок должен выдать $B$ штук, где центры данных прямоугольников внутри блока, но края могут выходить;\n",
    "    * Вероятность наличия объекта;\n",
    "    * Вероятность каждого класса **при условии** наличия объекта - окрашиваем блоки в цвета калссов (картинка ниже);\n",
    "\n",
    "<img src='img/lecture08/12.png'>\n",
    "\n",
    "### Качество \n",
    "\n",
    "<img src='img/lecture08/13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfdf60",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Идентификация объектов</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">3. DeepFace</h1>\n",
    "\n",
    "<img src='img/lecture08/15.png'>\n",
    "\n",
    "* Обучаем некоторую архитектуру для классификации (число классов = число людей в данных)\n",
    "* Используем выходы предпоследнего слоя как признаковое описание изображения\n",
    "* Признаки нормализуются (чтобы норма была единичной)\n",
    "* Лица похожих людей находятся в близких точках. Если на вход приходит новое лицо, которое пропускаем через нейронную сеть, получаем вектор. Считаем близость векторов по какой-нибудь метрике с лицами из базы, у которых векторы уже получены.\n",
    "\n",
    "\n",
    "Можно сравнить расстояние с порогом, чтобы идентифицировать человека, так как ближайший вектор может оказаться достаточно далеко. Порог позволяет не относить человека к таким случаем, мы просто не уверены в данной ситуации.\n",
    "\n",
    "Опять наблюдаем проблему, что задача решается в несколько этапов. Изначально примеются задачи классического компьютерного зрения для выделения лица. После, обучение нейронной сети извлекаем полезные признаки, прменяем метод ближайших соседей или что-то подобное. Хочется сразу обучать нейронную сеть на идентификацию лиц. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1ad3f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">3. FaceNet</h1>\n",
    "\n",
    "Почему бы в явном виде не обучать представления изображений так, чтобы фотографии одного человека имели близкие представления?\n",
    "\n",
    "Обучаем нейронную сеть на парах изображений. Необходимы фотографии, где на изображении один и тот же человек, и фотография другого человека.\n",
    "\n",
    "<img src='img/lecture08/16.png'>\n",
    "\n",
    "Нейронная сеть будет обучаться на триплетах. Один элемент обучающей выборки представляет собой тройку картинок. Первая картинка - это Anchor или же якорь. Positive - это фотография того же человека, Negative - фотография другого человека.\n",
    "\n",
    "<img src='img/lecture08/17.png'>\n",
    "\n",
    "Посмотрим на функцию потреь. Береём конкретную тройку, где $x_i^a$ - якорь из тройки, $x_i^p$ - человек того же класса. $x_i^n$ - другой человек. $f(x)$ - это векторное представление. Мы берём вектор якоря, считаем расстояние до того же человека. Дальше, считаем расстояние от якоря до другого человека. Считаем разницу между двумя расстояниями и прибавляем $\\alpha$ и выполняем положительную срезку ($z_+ = \\max (z, 0)$). Если выражение в скобках меньше нуля, тогда квадратные скобки будут равны нулю, а если выражение больше нуля, тогда квадратные скобки будут равны знечению под ними.\n",
    "\n",
    "Выражение внутри скобок будет отрицательным, если растояние до другого человка окажется больше, чем расстояние до того же человека + $\\alpha$, тогда ошибка будет равна нулю.\n",
    "\n",
    "Мы считаем Евклидово расстояние, так как мы обучаем пространство эмбеддингов так, чтобы Евклидово расстояние работало хорошо. На этапе применения имеется фотография владельца телефона, и то, что видит камера. Считаем расстояние между двумя фотографиями и если оно меньше некоторго порога, тогда говорим, что это один человек. Триплеты используются только на этапе обучаения, а на этапе применения мы используем признаковое описание из нейронной сети.\n",
    "\n",
    "### Выбор триплетов\n",
    "\n",
    "* Важно правильно выбирать триплеты\n",
    "* Обычно: выбираем positive и ищем semi-hard negatives\n",
    "\n",
    "$$\\large | f(x_i^a) - f(x_i^p)|_2^2 < | f(x_i^a) - f(x_i^n) |_2^2$$\n",
    "\n",
    "Правильнее всего взять якорь, взять позитивный пример и искать негативные такие, чтобы было выполнено данное условие. \n",
    "\n",
    "* Точность на LFW: 99.63%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
